---
title: "Modelo de regresión lineal. Ridge y Lasso"
author: "Jose Luis Canillas Cambronero"
date: "15/8/2020"
output: html_document
---

# 1. Regresión lineal. Predecir el beneficio.

Primero vamos a cargar los datos y las librerias necesarias, utilizamos la base de datos con los datos ya tipificados.


```{r include=FALSE}
movies <- read.csv("D:/Master_BigData/10.TFM/tfm_r/movies_mod.csv", header = TRUE, na = "NA")

library(tidyverse)
library(glmnet)
library(caret)
```

Seleccionamos unicamente las variables continuas y filtramos para eliminar los valores que no tenemos datos.

```{r}
data <- movies %>% select(budget,popularity,revenue,vote_average,vote_count)

data_d <- subset(data, budget > 1000 & revenue > 1000 )
```


Separamos los datos en conjunto de entrenamiento y de prueba.

```{r}
set.seed(100)

trainid <- sample(1:nrow(data_d), nrow(data_d)*0.8)
train <- data_d[trainid,]
test <- data_d[-trainid,]
```


Realizamos un pequeño modelo lineal, usando el conjunto de entrenamiento. Predecimos el beneficio en funcion del resto de variables.

```{r}
lmMod <- lm(revenue ~., data=train)
summary(lmMod)
```


Vemos que son significativas menos vote_average, lo excluimos y utilizamos las técnicas de regularización de ridge y lasso para ver si mejoramos el modelo.

```{r}
train <- train[, -4]
test <- test[, -4]
```

Para trabajar con glmnet, tenemos que pasar los dataframe de train y test a matrices, usando model.matrix.

```{r}
xmat.train <- model.matrix(revenue~., data=train)[,-1]
xmat.test <- model.matrix(revenue~., data=test)[,-1]
```

Realizamos validación cruzada para escoger el mejor valor de alpha.

```{r}
lasso.fit <- cv.glmnet(xmat.train, train$revenue, alpha = 1)
lasso.fit$lambda.min
```

Entrenamos el modelo lasso con el mejor valor de lambda

```{r}
model.lasso <- glmnet(xmat.train, train$revenue, alpha = 1, lambda = lasso.fit$lambda.min)
coef(model.lasso)
```

Realizamos predicciones

```{r}
lasso.pred <- model.lasso %>% predict(xmat.test) %>% as.vector()
```

Observamos las métricas para saber si el modelo ha mejorado

```{r}
data.frame(
  RMSE = RMSE(lasso.pred, test$revenue),
  Rsquare = R2(lasso.pred, test$revenue)
)

```

Y lo representamos gráficamente:

```{r}
plot(lasso.fit)
```


Realizamos el mismo proceso para ver si mejora también con con ridge:

```{r}
ridge.fit <- cv.glmnet(xmat.train, train$revenue, alpha = 0)
ridge.fit$lambda.min
```

```{r}
model.ridge <- glmnet(xmat.train, train$revenue, alpha = 0, lambda = lasso.fit$lambda.min)
coef(model.lasso)
```

```{r}
ridge.pred <- model.ridge %>% predict(xmat.test) %>% as.vector()
```

```{r}
data.frame(
  RMSE = RMSE(ridge.pred, test$revenue),
  Rsquare = R2(ridge.pred, test$revenue)
)
```

```{r}
plot(ridge.fit)
```

